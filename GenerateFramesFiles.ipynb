{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "source": [
    "# GenerateFramesFiles.ipynb\n",
    "\n",
    "### Notebook for generating frames files for LIGO data analysis, whether from NR simulation .h5 files, or using the a gravitational waveform surrogate model\n",
    "\n",
    "Maria Okounkova (mokounkova@flatironinstitute.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "source": [
    "### Imports and setup\n",
    "\n",
    "Note that the surrogate model methods will generate deprecation warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwtools/rotations.py:63: UserWarning: Could not import GWFrames, needed for rotations module\n",
      "  _warnings.warn(\"Could not import GWFrames, needed for rotations module\")\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwtools/__init__.py:11: UserWarning: Could not import rotations, decompositions, or fitfuncs. These are not needed by GWSurrogate.\n",
      "  _warnings.warn(\"Could not import rotations, decompositions, or fitfuncs. These are not needed by GWSurrogate.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting __package__ to gwsurrogate.new so relative imports work\n",
      "__name__ = gwsurrogate.new.spline_evaluation\n",
      "__package__= gwsurrogate.new\n",
      "setting __package__ to gwsurrogate.new so relative imports work\n",
      "setting __package__ to gwsurrogate.new so relative imports work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:245: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.t = h5file['t_ds'].value\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:272: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  'coefs': group['%s_coefs'%(key)].value,\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:273: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  'bfOrders': group['%s_bfOrders'%(key)].value\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:282: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  'coefs': group['%s_%d_coefs'%(key, i)].value,\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:283: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  'bfOrders': group['%s_%d_bfOrders'%(key, i)].value\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:733: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.t = h5file['t_coorb'].value\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:691: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  data['EI_basis'] = h5_group['EIBasis'].value\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:692: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  data['nodeIndices'] = h5_group['nodeIndices'].value\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:694: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  for i in range(len(data['nodeIndices']))]\n",
      "/home/maria.okounkova/.local/lib/python3.6/site-packages/gwsurrogate/new/precessing_surrogate.py:696: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  for i in range(len(data['nodeIndices']))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NRSur7dq4 model\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import h5py\n",
    "from astropy import constants as const\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "from pycbc.detector import Detector\n",
    "from gwpy.timeseries import TimeSeries\n",
    "from gwpy.detector import Channel\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import fileinput\n",
    "import seaborn as sns\n",
    "import math\n",
    "from math import pi\n",
    "import pycbc\n",
    "from pycbc.filter.matchedfilter import overlap\n",
    "import json\n",
    "from ipynb.fs.full.Auxiliary import ReadExtrapolatedModes, EvaluateSurrogate, SubtractPeakTime, dt_eval, df_eval, \\\n",
    "                                    PadAndProject, EllinKm, ComputeSNR, ComputeMultiDetectorSNR, TargetSNR\n",
    "import gwsurrogate\n",
    "## if you need the surrogate data: \n",
    "## gwsurrogate.catalog.pull('NRSur7dq4')\n",
    "\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rcParams['axes.labelsize'] = 30\n",
    "matplotlib.rcParams['xtick.labelsize'] = 24\n",
    "matplotlib.rcParams['ytick.labelsize'] = 24\n",
    "matplotlib.rcParams['xtick.major.size'] = 10\n",
    "matplotlib.rcParams['ytick.major.size'] = 10\n",
    "matplotlib.rcParams['xtick.top'] = True\n",
    "matplotlib.rcParams['xtick.direction'] = 'in'\n",
    "matplotlib.rcParams['xtick.minor.visible'] = True\n",
    "matplotlib.rcParams['xtick.minor.size'] = 5\n",
    "matplotlib.rcParams['ytick.minor.size'] = 5\n",
    "matplotlib.rcParams['legend.fontsize'] = 24\n",
    "matplotlib.rcParams['legend.frameon'] = True\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "\n",
    "sur = gwsurrogate.LoadSurrogate('NRSur7dq4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Helper functions for creating and reading injected parameter dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FullParamsDictionary(params_dict):\n",
    "    \"\"\" Given a total mass, q > 1, and spins a_1, a_2, in params_dict, \n",
    "        compute m_1, m_2, m_chirp, and chi_eff and add to params_dict\n",
    "         \"\"\"\n",
    "    mass = params_dict['mass']\n",
    "    q = params_dict['q']\n",
    "    a_1 = params_dict['a_1']\n",
    "    a_2 = params_dict['a_2']\n",
    "    \n",
    "    m_2 = mass / (1 + q)\n",
    "    m_1 = q*m_2\n",
    "    m_chirp = (q/(1+q)**2)**(3/5)*mass\n",
    "    \n",
    "    params_dict['m_1'] = m_1\n",
    "    params_dict['m_2'] = m_2\n",
    "    params_dict['mass_ratio'] = 1.0/q\n",
    "    params_dict['chirp_mass'] = m_chirp\n",
    "    \n",
    "    ## Assuming aligned spin for now \n",
    "    chi_eff = (a_1[2]/m_1 + a_2[2]/m_2)/mass\n",
    "    params_dict['chi_eff'] = chi_eff\n",
    "    \n",
    "    return params_dict\n",
    "\n",
    "def GetInjectedParameters(p):\n",
    "    \"\"\" Return a dictionary of values from the parameters.json file \n",
    "        corresponding to the frames, where p is the path to the file \"\"\"\n",
    "    \n",
    "    f = open(p + '/parameters.json')\n",
    "    params = json.load(f)\n",
    "    f.close()\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "source": [
    "### Frames files writing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def GenerateFrames(name, timeH, strainH, timeL, strainL, timeV, strainV, params_dict):\n",
    "    \"\"\" Generate frames files given hanford and livingston data.\n",
    "        rh_dir is the directory base directory for the data \n",
    "        Also make bayeswave files if necessary \"\"\"\n",
    "\n",
    "    frames_dir = 'BilbyPE/' + name + '/Frames/'\n",
    "    bilby_dir = 'BilbyPE/' + name + '/'\n",
    "    \n",
    "    os.makedirs(frames_dir)\n",
    "    \n",
    "    dt = dt_eval(timeH)\n",
    "\n",
    "    H1 = TimeSeries(strainH,sample_rate=1/dt,epoch=timeH[0],channel=\"H1:LDAS_STRAIN\")\n",
    "    L1 = TimeSeries(strainL,sample_rate=1/dt,epoch=timeL[0],channel=\"L1:LDAS_STRAIN\")\n",
    "    V1 = TimeSeries(strainV,sample_rate=1/dt,epoch=timeL[0],channel=\"V1:LDAS_STRAIN\")\n",
    "\n",
    "    H1.write(frames_dir + \"H1.gwf\")\n",
    "    L1.write(frames_dir + \"L1.gwf\")\n",
    "    V1.write(frames_dir + \"V1.gwf\")\n",
    "    \n",
    "    ## Copy over the bilby files and replace path variables\n",
    "    for file in ['aLIGOZeroDetHighPower-PSD_25Hz.txt', 'Frame.prior', 'Frames.py', \n",
    "                 'run_bilby.dag', 'run_bilby.sh', 'run_bilby.sub']:\n",
    "        \n",
    "        ## Copy over base file\n",
    "        copyfile('BilbyPE/Files/' + file, bilby_dir + file)\n",
    "        \n",
    "        ## Replace path variables\n",
    "        with fileinput.FileInput(bilby_dir + file, inplace=True) as f:\n",
    "            for line in f:\n",
    "                print(line.replace('FRAMES_DIR', name), end='')\n",
    "            \n",
    "    ## Logs directory for Bilby\n",
    "    os.mkdir(bilby_dir + 'Logs')\n",
    "    \n",
    "    ## Bayeswave files\n",
    "    bw_dir = bilby_dir + 'BayesWave'\n",
    "    os.mkdir(bw_dir)\n",
    "    \n",
    "    # Make the bayeswave cache files\n",
    "    start_dir = '/home/maria.okounkova/BeyondGRAnalysis/'\n",
    "    with open(bw_dir + '/H1_Cache.lcf', 'a') as file:\n",
    "        file.write(\"-\\t-\\t-\\t-\\tfile://localhost\" + start_dir + frames_dir + 'H1.gwf' + '\\n')\n",
    "    with open(bw_dir + '/L1_Cache.lcf', 'a') as file:\n",
    "        file.write(\"-\\t-\\t-\\t-\\tfile://localhost\" + start_dir + frames_dir + 'L1.gwf' + '\\n')\n",
    "    with open(bw_dir + '/V1_Cache.lcf', 'a') as file:\n",
    "        file.write(\"-\\t-\\t-\\t-\\tfile://localhost\" + start_dir + frames_dir + 'V1.gwf' + '\\n')\n",
    "\n",
    "    # Copy over the bayewave ini files\n",
    "    copyfile('run_bw.sh', bw_dir + '/run_bw.sh')\n",
    "    copyfile('dCS.ini', bw_dir + '/dCS.ini')\n",
    "    \n",
    "    # Change the path to the cache files in the copied dCS.ini file\n",
    "    with fileinput.FileInput(bw_dir + '/dCS.ini', inplace=True) as file:\n",
    "        for line in file:\n",
    "            print(line.replace('CACHE_DIR', bw_dir), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "source": [
    "### Create the frames files - evaluate the waveforms, project the data, and write frames files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def EvaluateNRWaveform(p_in, p_out, params_dict, desired_snr, ell = \"0p0\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a directory p_out in which the numerical relativity waveform lives (in an SXS format), \n",
    "    apply the astrophysical parameters given in params_dict to the waveform, and write frames\n",
    "    to directory p_out. \n",
    "    \n",
    "    desired_snr corresponds to the SNR we would like for the frames files, which is \n",
    "    achieved by adjusting the distance. \n",
    "    \"\"\"\n",
    "    time, h_plus, h_cross, amp = ReadExtrapolatedModes(p_in, params_dict, interpolate = False)\n",
    "    timeH, strainH, timeL, strainL, timeV, strainV = PadAndProject(time, h_plus, h_cross, params_dict, verbose = True)\n",
    "    \n",
    "    ## Update distance for target SNR\n",
    "    strainH, strainL, strainV, params_dict = TargetSNR(timeH, strainH, timeL, strainL, timeV, strainV, params_dict, desired_snr)\n",
    "    GenerateFrames(p_out, timeH, strainH, timeL, strainL, timeV, strainV, params_dict)\n",
    "    \n",
    "    ## Compute SNRs\n",
    "    SNR_H = ComputeSNR(timeH, strainH)\n",
    "    SNR_L = ComputeSNR(timeL, strainL)\n",
    "    SNR_V = ComputeSNR(timeV, strainV)\n",
    "    SNR = ComputeMultiDetectorSNR(timeH, strainH, timeL, strainL, timeV, strainV)\n",
    "    print(\"Network SNR: \", SNR)\n",
    "    \n",
    "    ## Print out the parameter values\n",
    "    params_dict = FullParamsDictionary(params_dict)\n",
    "    params_dict['source'] = p_in\n",
    "    params_dict['H_SNR'] = SNR_H\n",
    "    params_dict['L_SNR'] = SNR_L\n",
    "    params_dict['V_SNR'] = SNR_V\n",
    "    params_dict['SNR'] = SNR\n",
    "    params_dict['ell'] = ell \n",
    "    params_dict['ell_km'] = EllinKm(ell, params_dict['mass'])\n",
    "    with open('BilbyPE/' + p_out + '/parameters.json', 'w') as fp:\n",
    "        json.dump(params_dict, fp)\n",
    "    fp.close()\n",
    "\n",
    "def EvaluateSurrogateWaveform(p_out, params_dict, desired_snr):\n",
    "    \"\"\"\n",
    "    Given a directory dictionary of BBH parameters params_dict, evaluate the surrogate model \n",
    "    and write frames to directory p_out. \n",
    "    \n",
    "    desired_snr corresponds to the SNR we would like for the frames files, which is \n",
    "    achieved by adjusting the distance. \n",
    "    \"\"\"\n",
    "    time, h_plus, h_cross, amp = EvaluateSurrogate(sur, params_dict)\n",
    "    timeH, strainH, timeL, strainL, timeV, strainV = PadAndProject(time, h_plus, h_cross, params_dict)\n",
    "    \n",
    "    ## Update distance for target SNR\n",
    "    strainH, strainL, params_dict = TargetSNR(timeH, strainH, timeL, strainL, timeV, strainV, params_dict, desired_snr)\n",
    "    GenerateFrames(p_out, timeH, strainH, timeL, strainL, timeV, strainV, params_dict)\n",
    "    \n",
    "    ## Compute SNRs\n",
    "    SNR_H = ComputeSNR(timeH, strainH)\n",
    "    SNR_L = ComputeSNR(timeL, strainL)\n",
    "    SNR_V = ComputeSNR(timeV, strainV)\n",
    "\n",
    "    ## Print out the parameter values\n",
    "    params_dict = FullParamsDictionary(params_dict)\n",
    "    params_dict['H_SNR'] = SNR_H\n",
    "    params_dict['L_SNR'] = SNR_L\n",
    "    params_dict['V_SNR'] = SNR_V\n",
    "    with open('BilbyPE/' + p_out + '/parameters.json', 'w') as fp:\n",
    "        json.dump(params_dict, fp)\n",
    "    fp.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually generate frames files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "t0 parameter:  1126259462.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ErfaWarning: ERFA function \"dtf2d\" yielded 1 of \"dubious year (Note 6)\" [astropy._erfa.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time delay between detectors -0.006985699700979881 -0.004281157268499984\n",
      "geocenter time delay H:  0.014694082894586626\n",
      "geocenter time delay L:  0.007708383193606742\n",
      "geocenter time delay V:  0.010412925626086639\n",
      "Peak time in H initially: 0.00046890974044799805\n",
      "Peak time in H updated: 1126259462.0\n",
      "Peak time in L updated: 1126259461.989565\n",
      "Peak time in V updated: 1126259461.9926715\n",
      "Segment start and end:  1126259454.0 1126259470.0\n",
      "t0 is in the time array:  True\n",
      "Peak time in H after interpolation: 1126259462.0\n",
      "Peak time in L after interpolation: 1126259461.989746\n",
      "Peak time in V after interpolation: 1126259461.9926758\n",
      "Current SNR  112.69448184926898\n",
      "Current distance 400.0\n",
      "Updated distance 450.7779273970759\n",
      "Network SNR:  100.0\n"
     ]
    }
   ],
   "source": [
    "# ## Parameters under consideration for this study\n",
    "My_Params_Dict = {'dt' : 1/2048, 't_gps' : 1126259462.0, 'peak_time_in_segment' : 8.0, 'segment_length' : 16.0, \\\n",
    "               'dist_mpc' : 400.0, 'mass' : 68.0, 'q' : 1.2212532137858916, \\\n",
    "               'a_1' : [0, 0, 0.329892752405], 'a_2' : [0, 0, -0.439940981499], \\\n",
    "               'f_low' : 0, 'theta' : pi, 'phi' : 0, \\\n",
    "               'ra' : 1.952318922, 'dec' : -1.26967171703, 'pol' : 0.824043851821}\n",
    " \n",
    "\n",
    "for SNR in [100]:\n",
    "    for ell in ['0p0']:\n",
    "        print('--------------------------------------------')\n",
    "        EvaluateNRWaveform('Waveforms/Lev5/dCS_Strain_' + ell + '.h5', 'PHENOM_dCS_' + ell + '_' + str(SNR), My_Params_Dict, SNR, ell=ell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Plot the frame files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def PlotInjectedWaveforms():\n",
    "    \n",
    "    \"\"\" Produce a plot of injected waveforms read from frames files \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    base = '/home/maria.okounkova/BeyondGRAnalysis/BilbyPE/'\n",
    "\n",
    "    ## Get injected paramters\n",
    "    p = base + 'PHENOM_dCS_0p0_75'\n",
    "    params = GetInjectedParameters(p)\n",
    "    print(params)\n",
    "    \n",
    "    for det in [\"H1\", \"L1\", \"V1\"]:\n",
    "        strain = TimeSeries.read(source = p + '/Frames/' + det + '.gwf', channel=det+\":LDAS_STRAIN\")\n",
    "        time = np.array(strain.times)\n",
    "        plt.plot(time, strain, '-', lw=1.5, label = det)\n",
    "\n",
    "    t_gps = 1126259462.0\n",
    "    plt.xlim(t_gps - 1.0, t_gps + 0.2)\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylabel(r'$h(t)$')\n",
    "    legend = plt.legend(fontsize=24, loc = 'lower left', ncol=2, frameon=False)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('InjectedWaveforms.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "#PlotInjectedWaveforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
