{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d9befc-66a1-4fc9-aba8-c5e963d7bf8f",
   "metadata": {},
   "source": [
    "# Auxiliary.ipynb\n",
    "\n",
    "#### Notebook containing computations that multiple data analysis notebooks need, such as waveform reading, surrogate evaluation, overlap computation, and SNR computation\n",
    "\n",
    "Maria Okounkova (mokounkova@flatironinstitute.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ec9447-9f99-448d-b70f-00e5a3d6e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from astropy import constants as const\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import matplotlib\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import gwsurrogate\n",
    "from pycbc.detector import Detector\n",
    "import pycbc\n",
    "from pycbc.filter.matchedfilter import overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680e424-d9b8-4232-8778-87fb429eca84",
   "metadata": {
    "tags": []
   },
   "source": [
    "### General auxiliary methods - subtracting peak times, computing $\\Delta t$, ramp function, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e2057d-d099-4c07-abfa-94c009ff9e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPeakTime(time, data): \n",
    "    \"\"\" Grab the peak time of some data \"\"\"\n",
    "    t_peak = time[np.argmax(data)]\n",
    "    return t_peak\n",
    "\n",
    "def SubtractPeakTime(time, data): \n",
    "    \"\"\" Subtract the peak time of some data \"\"\"\n",
    "    t_peak = GetPeakTime(time, data)\n",
    "    return time - t_peak\n",
    "\n",
    "def dt_eval(time):\n",
    "    \"\"\" Return the time step of a given time array \"\"\"\n",
    "    return (time[1] - time[0])\n",
    "\n",
    "def df_eval(time):\n",
    "    \"\"\" Return the delta_f of a given time array \"\"\"\n",
    "    delta_t = dt_eval(time)\n",
    "    return 1.0/((time[-1] - time[0]) + delta_t)\n",
    "\n",
    "def Ramp(time, t_s, t_r):\n",
    "    \"\"\" Ramp function for tapering the waveform\"\"\"\n",
    "    if (time < t_s):\n",
    "        return 0.0\n",
    "    elif time > (t_s + t_r):\n",
    "        return 1.0\n",
    "    else:\n",
    "        t = (time - t_s)/t_r\n",
    "        return t**5*(126 + t*(-420 + t*(540 + t*(-315 + 70*t))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12659527-d2a0-47de-802c-95752ca17df9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### dCS auxiliary methods - converting dimensionless coupling constant to kms, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edee3463-620d-4a9c-9d92-df05fb7bb740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EllinKm(ell, mass):\n",
    "    \"\"\" Return the value of the dCS coupling constant in km \"\"\"\n",
    "    if 'p' in ell:\n",
    "        ## If we're using a string like 0p0 for 0.0, convert to a float\n",
    "        ell = float(ell.replace('p', '.'))\n",
    "    mass_msun = mass * const.M_sun\n",
    "    phys_ell_km = ell * mass_msun * const.G /(const.c**2) / 1000\n",
    "    return phys_ell_km.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143fc0b-41f2-4a98-a67e-68c92f3140af",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NR auxiliary methods - waveform reading methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f18649f-cfa1-4ee0-b926-968609a3a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swsh(s, modes, theta, phi, psi=0):\n",
    "    \"\"\"\n",
    "    Return a value of a spin-weighted spherical harmonic of spin-weight s. \n",
    "    If passed a list of several modes, then a numpy array is returned with \n",
    "    SWSH values of each mode for the given point.\n",
    "    For one mode:       swsh(s,[(l,m)],theta,phi,psi=0)\n",
    "    For several modes:  swsh(s,[(l1,m1),(l2,m2),(l3,m3),...],theta,phi,psi=0)\n",
    "    \"\"\"\n",
    "    import spherical_functions as sf\n",
    "    import quaternion as qt\n",
    "    return sf.SWSH(qt.from_spherical_coords(theta, phi), s, modes) * np.exp(1j * s * psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2431fe-7faf-4e99-9706-414efdbaf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadExtrapolatedModes(file, params_dict, interpolate = True):\n",
    "    \"\"\" \n",
    "        File is the file containing the extrapolated waveform that we want to read in.\n",
    "        For params_dict, \n",
    "        mass_msun is the total mass of the system in solar masses, and \n",
    "        dist_mpc is the distance to the system in kpc. \n",
    "        theta and phi are angles determining the inclination.\n",
    "        dt is the timestep (reciprocal of the sampling rate)\n",
    "        \n",
    "        If we want to interpolate the waveform to have even timesteps dt, then \n",
    "        set interpolate to True. Otherwise, we'll return the data without \n",
    "        performing the interpolation \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    ## Convert distance to kpc and mass into solar masses\n",
    "    mass = params_dict['mass']\n",
    "    dist_mpc = params_dict['dist_mpc']\n",
    "    theta = params_dict['theta']\n",
    "    phi = params_dict['phi'] \n",
    "    dt = params_dict['dt']\n",
    "    dist_kpc = dist_mpc * 1000 * const.kpc\n",
    "    mass_msun = mass * const.M_sun\n",
    "    \n",
    "    ## Read in the data\n",
    "    f = h5py.File(file, 'r')\n",
    "    \n",
    "    ## grab the length of the waveform first\n",
    "    data = f['Extrapolated_N2.dir']['Y_l2_m2.dat']\n",
    "    time = np.array(data[:,0])\n",
    "    \n",
    "    h_plus = np.zeros(len(time))\n",
    "    h_cross = np.zeros(len(time))\n",
    "\n",
    "    modes = [(l,m) for l in range(2,5) for m in range(-l, l+1)]\n",
    "    for mode in modes: \n",
    "        \n",
    "        ## Grab the mode in question\n",
    "        l = mode[0]\n",
    "        m = mode[1]\n",
    "        \n",
    "        data = f['Extrapolated_N2.dir']['Y_l' + str(l) + '_m' + str(m) + '.dat']\n",
    "        real = np.array(data[:,1])\n",
    "        imag = np.array(data[:,2])\n",
    "        coeff = real + 1j * imag\n",
    "        \n",
    "        ## Multiply by the corresponding spin-weighted spherical harmonic\n",
    "        Ylm = swsh(-2, [(l,m)], theta=theta, phi=phi, psi=0) \n",
    "        h = coeff * Ylm \n",
    "        \n",
    "        ## Add to our h_plus and h_cross computations\n",
    "        h_plus = h_plus + np.real(h)\n",
    "        h_cross = h_cross - np.imag(h) \n",
    "        \n",
    "    ## Apply the astrophysical parameters\n",
    "    time = time*mass_msun*const.G/(const.c**3)\n",
    "    h_plus = h_plus*const.G*mass_msun/((const.c)**2*dist_kpc)\n",
    "    h_cross = h_cross*const.G*mass_msun/((const.c)**2*dist_kpc)\n",
    "\n",
    "    ## Taper the waveform and apply the ramp (need to start the waveform at zero for this)\n",
    "    time = time - time[0]\n",
    "    ramp = np.array([Ramp(t.value, 0.1, 0.3) for t in time])\n",
    "    \n",
    "    h_plus = h_plus * ramp\n",
    "    h_cross = h_cross * ramp\n",
    "    \n",
    "    ## Now subtract off the peak time (this makes the spine interpolation easier)\n",
    "    amp = np.sqrt(h_plus**2 + h_cross**2)\n",
    "    time = time - time[np.argmax(amp)]\n",
    "    \n",
    "    if not interpolate:\n",
    "        print(\"Not performing the interpolation\")\n",
    "        return time, h_plus, h_cross, np.sqrt(h_plus**2 + h_cross**2)\n",
    "    \n",
    "    ## Now build the interpolants \n",
    "    cs_plus = InterpolatedUnivariateSpline(time, h_plus)\n",
    "    cs_cross = InterpolatedUnivariateSpline(time, h_cross)\n",
    "\n",
    "    ## Now create an evenly-spaced time array and interpolate the data \n",
    "    time_cs = np.arange(time[0].value, time[-1].value, dt)\n",
    "\n",
    "    h_plus_cs = cs_plus(time_cs) \n",
    "    h_cross_cs = cs_cross(time_cs) \n",
    "    \n",
    "    ## Return these new interpolated values\n",
    "    return time_cs, h_plus_cs, h_cross_cs, np.sqrt(h_plus_cs**2 + h_cross_cs**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4b8d5-51c1-4494-a6dc-8a8f236bb14f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Surrogate auxiliary methods - surrogate model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65ffece2-baa8-4e8c-813f-7151f54d23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateSurrogate(sur, params_dict):\n",
    "    \"\"\" Evaluate the surrogate waveform using a dictionary of parameters\n",
    "        and an instance of a surrogate model \"\"\"\n",
    "\n",
    "    data = sur(params_dict['q'], params_dict['a_1'], params_dict['a_2'], \\\n",
    "               dt = params_dict['dt'], units = 'mks', M = params_dict['mass'], \\\n",
    "               dist_mpc = params_dict['dist_mpc'], f_low = params_dict['f_low'], \\\n",
    "               inclination = params_dict['theta'], ellMax = 4, \\\n",
    "               phi_ref = params_dict['phi'])\n",
    "\n",
    "    time = np.array(data[0])\n",
    "    h_plus = np.real(data[1])\n",
    "    h_cross = -1 * np.imag(data[1])\n",
    "\n",
    "    ## Taper the waveform and apply the ramp (need to start the waveform at zero for this)\n",
    "    #time = time - time[0]\n",
    "    #ramp = np.array([Ramp(t, 0.1, 0.3) for t in time])\n",
    "    \n",
    "    #h_plus = h_plus * ramp\n",
    "    #h_cross = h_cross * ramp\n",
    "    \n",
    "    ## Subtract off the peak time of the waveform\n",
    "    amp = np.sqrt(h_plus**2 + h_cross**2)\n",
    "    time = time - time[np.argmax(amp)]\n",
    "    \n",
    "    return time, h_plus, h_cross, np.sqrt(h_plus**2 + h_cross**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c6aec7-e073-4d53-87a0-2b430e415657",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Detector auxiliary methods - $h_\\times$ and $h_\\times$ to detectors, padding time segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d12393-cf01-4c69-9753-44eb12bd565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjectToDetectors(ra, dec, pol, t0, plus, cross, time):\n",
    "    \"\"\"\n",
    "    Given plus and cross gravitational waveforms as a function of time, \n",
    "    project to H1 and L1 using the angles: \n",
    "    ra - Right Ascension\n",
    "    dec - Declination\n",
    "    pol - Polarization Angle\n",
    "    t0 - reference time for when signal reaches Hanford\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Grab the dt\n",
    "    dt = dt_eval(time)\n",
    "    \n",
    "    d_H1 = Detector(\"H1\")\n",
    "    d_L1 = Detector(\"L1\")\n",
    "    \n",
    "    # The time delay of the signal between the detectors\n",
    "    t_delay_LH = d_L1.time_delay_from_detector(d_H1, ra, dec, t0)\n",
    "    \n",
    "    # Round the delay time to the nearest dt (this assumes that t_gps is a multiple of dt)\n",
    "    t_delay_rounded_LH = round(t_delay_LH / dt) * dt\n",
    "\n",
    "    #Antenna Patterns\n",
    "    Fp_H1, Fc_H1 = d_H1.antenna_pattern(ra, dec, pol, t0)\n",
    "    Fp_L1, Fc_L1 = d_L1.antenna_pattern(ra, dec, pol, t0 + t_delay_rounded_LH)\n",
    "    \n",
    "    #project\n",
    "    h_H1 = Fp_H1*plus + Fc_H1*cross\n",
    "    h_L1 = Fp_L1*plus + Fc_L1*cross\n",
    "    \n",
    "    #Shift times\n",
    "    time_H1 = time\n",
    "    time_L1 = time + t_delay_rounded_LH\n",
    "    \n",
    "    return time_H1, h_H1, time_L1, h_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5338332-405d-4a4e-902d-f2315386e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PadZeroes(time, strain, t_gps, peak_time_in_segment, segment_length):\n",
    "    \"\"\" \n",
    "    Given strain data as a function of time, pad the data with zeros in order\n",
    "    to obtain a desired segment_length, where\n",
    "    \n",
    "    t_gps: gps peak time of the signal\n",
    "    peak_time_in_segmnet: how far into the segment we want the peak of the waveform to be\n",
    "    segment_length: the total length of the segment \n",
    "    \"\"\"\n",
    "\n",
    "    ## Pad the data with zeros -- we want to pad both the H1 and L1 data so that \n",
    "    ## they span the same gps times\n",
    "    dt = dt_eval(time)\n",
    "    segment_start_time = t_gps - peak_time_in_segment\n",
    "    segment_end_time = segment_start_time + segment_length\n",
    "    \n",
    "    ## Do Hanford first (see how much we need to pad in order to get )\n",
    "    start_pad_time = time[0] - segment_start_time\n",
    "    end_pad_time = segment_end_time - time[-1]\n",
    "    \n",
    "    ## Figure out how many integer zeroes to pad the data\n",
    "    start_pad_zeros = start_pad_time / dt\n",
    "    end_pad_zeros = end_pad_time / dt\n",
    "    \n",
    "    ## Pad the data with zeroes \n",
    "    strain_padded = np.pad(strain, (int(start_pad_zeros), int(end_pad_zeros)), 'constant', constant_values=(0.0, 0.0))\n",
    "    time_padded = np.arange(0., segment_length + dt, dt) + segment_start_time\n",
    "    if (len(time_padded) > len(strain_padded)):\n",
    "        time_padded = np.arange(0., segment_length, dt) + segment_start_time\n",
    "\n",
    "    return time_padded, strain_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849bbce8-9448-4912-9e29-e6f4f23d7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PadAndProject(time, h_plus, h_cross, params_dict):\n",
    "    \"\"\" Given a time, h_plus, and h_cross array, pad the data to the desired segment length, and project \n",
    "        to detectors.\n",
    "        Within params_dict, \n",
    "        t_gps is the gps time of the event\n",
    "        peak_time_in_segment is the time within the segment corresponding to the peak of the waveform (in sec)\n",
    "        segmentt_length is the length of the segment (in sec)\n",
    "        ra is the right ascention\n",
    "        dec is the declination\n",
    "        pol is the polarization\n",
    "    \"\"\"\n",
    "       \n",
    "    ## Grab the dt\n",
    "    dt = dt_eval(time)\n",
    "    \n",
    "    ## The present peak time in the gravitational waveform (in secs)\n",
    "    ## This is not the gps time, but rather should be ~0 from the surrogate / NR waveform \n",
    "    t_peak = time[np.argmax(h_plus**2 + h_cross**2)]\n",
    "    \n",
    "    ## Shift the times by the gps time, so that the peak of the waveform (in Handford)\n",
    "    ## is now at t_gps\n",
    "    time = time + params_dict['t_gps']\n",
    "\n",
    "    ## Double check the peak time\n",
    "    t_peak = time[np.argmax(h_plus**2 + h_cross**2)]\n",
    "    \n",
    "    ## Project data to the detectors -- both timeH and timeL % dt will be zero\n",
    "    timeH, strainH, timeL, strainL = ProjectToDetectors(ra=params_dict['ra'], dec=params_dict['dec'], \\\n",
    "                                                        pol=params_dict['pol'], t0=params_dict['t_gps'], \\\n",
    "                                                        plus=h_plus, cross=h_cross, time=time)\n",
    "    \n",
    "    ## Pad the data with zeros\n",
    "    timeH, strainH = PadZeroes(timeH, strainH, params_dict['t_gps'], params_dict['peak_time_in_segment'], \\\n",
    "                                               params_dict['segment_length'])\n",
    "    timeL, strainL = PadZeroes(timeL, strainL, params_dict['t_gps'], params_dict['peak_time_in_segment'], \\\n",
    "                                               params_dict['segment_length'])\n",
    "    \n",
    "    ## Return the projected data\n",
    "    return timeH, strainH, timeL, strainL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f773a3-4d36-4126-9e70-7be839db0d9e",
   "metadata": {},
   "source": [
    "### SNR and Overlap Auxiliary methods - Computing single and multi detector overlaps, computing SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "297afd09-ce8c-470f-be20-7b32d3282692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeInnerProduct(time1, strain1, time2, strain2, normalized = False):\n",
    "    \"\"\" Given two time-domain strains and the corresponding time arrays, compute the \n",
    "        inner product in one detector using pycbc. \n",
    "        Use normalized = True for overlaps, and normalized = False for SNR\n",
    "        Assuming that this is Eq. 4 in https://arxiv.org/abs/2003.09456\n",
    "        If we want it normalized, then it's like Eq. 8 in https://arxiv.org/abs/2003.09456\n",
    "    \"\"\"\n",
    "\n",
    "    ## Construct time array to be interpolated onto, since the pycbc overlap computation\n",
    "    ## requires the time arrays to be the same\n",
    "    delta_t = dt_eval(time1)\n",
    "    time = np.arange(start = max(time1[0], time2[0]), stop = min(time1[-1], time2[-1]), step = delta_t)\n",
    "    delta_f = df_eval(time)\n",
    "    \n",
    "    ## Interpolate strains onto time array\n",
    "    cs1 = InterpolatedUnivariateSpline(time1, strain1)\n",
    "    cs2 = InterpolatedUnivariateSpline(time2, strain2)\n",
    "    \n",
    "    strain1 = cs1(time) \n",
    "    strain2 = cs2(time)\n",
    "\n",
    "    ## Read in PSD and construct interpolant\n",
    "    psd_file = \"PSDs/design/aLIGOZeroDetHighPower-PSD.txt\"\n",
    "    psd_frequencies, psd_vals = np.loadtxt(psd_file, comments=\"#\",usecols=([0,1]),unpack=True)\n",
    "    cs = InterpolatedUnivariateSpline(psd_frequencies, psd_vals)\n",
    "\n",
    "    ## Interpolated PSD onto df-spaced values\n",
    "    freqs = delta_f * np.array(range(len(time)))\n",
    "    psd = cs(freqs)\n",
    "\n",
    "    ## Timeseries and Frequency series objects for pycbc computation\n",
    "    strain1_ts = pycbc.types.timeseries.TimeSeries(strain1, delta_t = delta_t, epoch = time[0])\n",
    "    strain2_ts = pycbc.types.timeseries.TimeSeries(strain2, delta_t = delta_t, epoch = time[0])\n",
    "    psd_fs = pycbc.types.frequencyseries.FrequencySeries(psd, delta_f = delta_f, epoch = time[0])\n",
    "\n",
    "    overlap_val = overlap(vec1 = strain1_ts, vec2 = strain2_ts, psd = psd_fs, normalized = normalized, \\\n",
    "                          low_frequency_cutoff = 25, high_frequency_cutoff = 2048) \n",
    "    \n",
    "    return overlap_val\n",
    "\n",
    "def ComputeOverlap(time1, strain1, time2, strain2):\n",
    "    \"\"\" Compute overlap in one detector - Eq. 8 in arxiv.org/abs/2003.09456\n",
    "    \"\"\"\n",
    "    inner_product = ComputeInnerProduct(time1, strain1, time2, strain2, normalized = True)\n",
    "    return np.sqrt(inner_product)\n",
    "\n",
    "def ComputeMultiDetectorInnerProduct(time1_H, strain1_H, time1_L, strain1_L, \\\n",
    "                                time2_H, strain2_H, time2_L, strain2_L):\n",
    "    \"\"\" Given two strain waveforms in both H1 and L1, compute the multi-detector inner product.\n",
    "        Use normalized = True for overlaps, and normalized = False for SNR.\n",
    "        This is Eq. 3 in arxiv.org/abs/2003.09456\n",
    "    \"\"\"\n",
    "    \n",
    "    inner_H = ComputeInnerProduct(time1_H, strain1_H, time2_H, strain2_H, normalized = False)\n",
    "    inner_L = ComputeInnerProduct(time1_L, strain1_L, time2_L, strain2_L, normalized = False)\n",
    "    ## Sum the detector results\n",
    "    return inner_H + inner_L\n",
    "\n",
    "def ComputeMultiDetectorOverlap(time1_H, strain1_H, time1_L, strain1_L, \\\n",
    "                                time2_H, strain2_H, time2_L, strain2_L):\n",
    "    \n",
    "    \"\"\" Compute the overlap between two two-detector signals using Eq. 8 of arxiv.org/abs/2003.09456\n",
    "    \"\"\"\n",
    "    \n",
    "    ## numerator term\n",
    "    O_AB = ComputeMultiDetectorInnerProduct(time1_H, strain1_H, time1_L, strain1_L, \\\n",
    "                                time2_H, strain2_H, time2_L, strain2_L)\n",
    "    \n",
    "    ## denominator terms\n",
    "    O_AA = ComputeMultiDetectorInnerProduct(time1_H, strain1_H, time1_L, strain1_L, \\\n",
    "                                time1_H, strain1_H, time1_L, strain1_L)\n",
    "    O_BB = ComputeMultiDetectorInnerProduct(time2_H, strain2_H, time2_L, strain2_L, \\\n",
    "                                time2_H, strain2_H, time2_L, strain2_L)\n",
    "    \n",
    "    result = O_AB / np.sqrt(O_AA * O_BB)\n",
    "    return result\n",
    "    \n",
    "\n",
    "def ComputeSNR(time, strain):\n",
    "    \"\"\" Given a time-domain strain and the corresponding time array, \n",
    "        compute the SNR using pycbc in one detector \n",
    "        Using Eq. 5 in arxiv.org/abs/2003.09456 \"\"\"\n",
    "    \n",
    "    inner_product = ComputeInnerProduct(time, strain, time, strain, normalized = False)\n",
    "    return np.sqrt(inner_product)\n",
    "\n",
    "\n",
    "def ComputeMultiDetectorSNR(timeH, strainH, timeL, strainL):\n",
    "    \"\"\" Compute an SNR in multiple detectors using Eq. 5 in arxiv.org/abs/2003.09456 \n",
    "    \"\"\"\n",
    "    \n",
    "    inner_product_H = ComputeInnerProduct(timeH, strainH, timeH, strainH, normalized = False)\n",
    "    inner_product_L = ComputeInnerProduct(timeL, strainL, timeL, strainL, normalized = False)\n",
    "    result = np.sqrt(inner_product_H + inner_product_L)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0790b-a3bf-4413-b259-0c69d7a34033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
